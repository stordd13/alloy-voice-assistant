{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.11.4)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/bstordeur/Documents/alloy-voice-assistant/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "from threading import Lock, Thread\n",
    "\n",
    "import cv2\n",
    "import openai\n",
    "from cv2 import VideoCapture, imencode\n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.schema.messages import SystemMessage\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from pyaudio import PyAudio, paInt16\n",
    "from speech_recognition import Microphone, Recognizer, UnknownValueError\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.11.4)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/bstordeur/Documents/alloy-voice-assistant/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "class WebcamStream:\n",
    "    def __init__(self):\n",
    "        self.stream = VideoCapture(index=0)\n",
    "        _, self.frame = self.stream.read()\n",
    "        self.runnig = False\n",
    "        self.lock = Lock()\n",
    "    \n",
    "    def start(self):\n",
    "\n",
    "        if self.running:\n",
    "            return self\n",
    "        \n",
    "        self.running = True\n",
    "\n",
    "        self.thread = Thread(target=self.update, args=())\n",
    "        self.thread.start()\n",
    "        return self\n",
    "    \n",
    "    def update(self):\n",
    "        while self.running:\n",
    "            _, frame = self.stream.read()\n",
    "\n",
    "            self.lock.acquire()\n",
    "            self.frame = frame\n",
    "            self.lock.release()\n",
    "    \n",
    "    def read(self, encode=False):\n",
    "        self.lock.acquire()\n",
    "        frame = self.frame.copy()\n",
    "        self.lock.release()\n",
    "\n",
    "        if encode:\n",
    "            _, buffer = imencode(\".jpeg\", frame)\n",
    "            return base64.b64encode(buffer)\n",
    "    \n",
    "        return frame\n",
    "    \n",
    "    def stop(self):\n",
    "        self.running = False\n",
    "        if self.thread.is_alive():\n",
    "            self.thread.join()\n",
    "        \n",
    "    def __exit__(self, exc_type, exc_value, exc_traceback):\n",
    "        self.stream.realease()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Assistant:\n",
    "    def __init__(self, model):\n",
    "        self.chain = self._create_inference_chain(model)\n",
    "\n",
    "    def answer(self, prompt, image):\n",
    "        if not prompt:\n",
    "            return\n",
    "        \n",
    "        print(\"Prompt:\", prompt)\n",
    "\n",
    "        response = self.chain.invoke(\n",
    "            {\"prompt\":prompt, \"image_base64\":image.decode()},\n",
    "            config={\"configurable\": {\"session_id\":\"unused\"}}\n",
    "        ).strip()\n",
    "\n",
    "        print(\"Response\", response)\n",
    "\n",
    "        if response:\n",
    "            self._tts(self, response)\n",
    "    \n",
    "    def _tts(self, response):\n",
    "\n",
    "        player = PyAudio().open(format=paInt16,channel=1, rate=24000, output=True)\n",
    "\n",
    "        with openai.audio.speech.with_streaming_response.create(\n",
    "            model=\"tts-1\",\n",
    "            voice=\"alloy\",\n",
    "            response_format=\"pcm\",\n",
    "            input=response\n",
    "        ) as stream:\n",
    "            for chunk in stream.iter_bytes(chunk_size=1024):\n",
    "                player.write(chunk)\n",
    "    \n",
    "\n",
    "    def _create_inference_chain(self, model):\n",
    "\n",
    "        SYSTEM_PROMPT = \"\"\"\n",
    "        You are a witty assistant that will use the chat history and the image\n",
    "        provided by the user to answer its question. \n",
    "\n",
    "        Use few words on your answer. Go straight to the point. Do not use any\n",
    "        emoticons or emojis. Do not ask the user any questions.\n",
    "\n",
    "        Be friendly and helpful. Show some personality. Do not be too formal.\n",
    "        \"\"\"\n",
    "\n",
    "        prompt_template = ChatPromptTemplate.from_message(\n",
    "            [\n",
    "                SystemMessage(contnt=SYSTEM_PROMPT),\n",
    "                MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                (\n",
    "                    \"human\",\n",
    "                    [\n",
    "                        {\"type\":\"text\", \"text\":{\"prompt\"}},\n",
    "                        {\n",
    "                            \"type\":\"image_url\",\n",
    "                            \"image_url\":\"data:image/jpeg;base64,{image_base64}\",\n",
    "                        },\n",
    "                    ],\n",
    "                ),\n",
    "            ],\n",
    "        )\n",
    "        chain = prompt_template | model | StrOutputParser()\n",
    "\n",
    "        chat_message_history = ChatMessageHistory()\n",
    "        return RunnableWithMessageHistory(\n",
    "            chain, \n",
    "            lambda _: chat_message_history,\n",
    "            input_message_key='prompt',\n",
    "            history_messages_key=\"chat_history\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webcam_stream = WebcamStream().start()\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "assistant = Assistant(model)\n",
    "\n",
    "def audio_callback(recognizer, audio):\n",
    "    try:\n",
    "        prompt = recognizer.recognize_whisper(audio, model=\"base\", language=\"engish\")\n",
    "        assistant.answer(prompt, webcam_stream.read(encode=True))\n",
    "    \n",
    "    except UnknownValueError:\n",
    "        print(\"There was an error processing the audio.\")\n",
    "    \n",
    "recognizer = Recognizer()\n",
    "microphone = Microphone()\n",
    "\n",
    "with microphone as source:\n",
    "    recognizer.adjust_for_ambient_noise(source)\n",
    "\n",
    "stop_listening = recognizer.listen_in_background(microphone, audio_callback)\n",
    "\n",
    "while True:\n",
    "    cv2.imshow(\"webcam\", webcam_stream.read())\n",
    "    if cv2.waitKey(1) in [27, ord(\"q\")]:\n",
    "        break\n",
    "    webcam_stream.stop()\n",
    "    cv2.destroyAllWindows()\n",
    "    stop_listening(wait_for_stop=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
